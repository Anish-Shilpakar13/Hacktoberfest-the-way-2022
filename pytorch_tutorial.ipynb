{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0.])\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [8.9633e-33, 4.7562e+30, 9.2860e-04]],\n",
      "\n",
      "        [[7.5031e+28, 6.2618e+22, 4.7428e+30],\n",
      "         [2.9514e+29, 1.8037e+28, 8.6468e-01],\n",
      "         [4.5144e+27, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00]]])\n"
     ]
    }
   ],
   "source": [
    "# param is size\n",
    "# 1D\n",
    "x = torch.empty(3)\n",
    "# 2D\n",
    "y = torch.empty(3,2)\n",
    "# 3D\n",
    "z = torch.empty(3,3,3)\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6971, 0.7141],\n",
      "        [0.2155, 0.6328]])\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Random\n",
    "x = torch.rand(2,2)\n",
    "print(x)\n",
    "# Zeros\n",
    "x = torch.zeros(2,2)\n",
    "print(x)\n",
    "# Ones\n",
    "x = torch.ones(2,2)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.int32\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "# Check data type\n",
    "print(x.dtype)\n",
    "# Specify data type\n",
    "x = torch.ones(2,2,dtype=torch.int)\n",
    "print(x.dtype)\n",
    "# size\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.5000, 0.1000])\n"
     ]
    }
   ],
   "source": [
    "# Creating tensor from lists \n",
    "x = torch.tensor([2.5,0.1])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9280, 0.8099],\n",
      "        [0.7316, 0.5522]])\n",
      "tensor([[0.0753, 0.8483],\n",
      "        [0.8375, 0.5096]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2,2)\n",
    "y = torch.rand(2,2)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Arithmetic Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0033, 1.6582],\n",
      "        [1.5692, 1.0618]])\n",
      "tensor([[1.0033, 1.6582],\n",
      "        [1.5692, 1.0618]])\n"
     ]
    }
   ],
   "source": [
    "# Element wise addition\n",
    "z = x + y\n",
    "print(z)\n",
    "z = torch.add(x,y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0033, 1.6582],\n",
      "        [1.5692, 1.0618]])\n"
     ]
    }
   ],
   "source": [
    "# Inplace addition\n",
    "# in pytorch trailing _ means inplace operations\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0753, -0.8483],\n",
      "        [-0.8375, -0.5096]])\n",
      "tensor([[-0.0753, -0.8483],\n",
      "        [-0.8375, -0.5096]])\n"
     ]
    }
   ],
   "source": [
    "# Element wise subtraction\n",
    "z = x - y\n",
    "print(z)\n",
    "z = torch.sub(x,y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9311, 1.3430],\n",
      "        [1.1480, 0.5864]])\n",
      "tensor([[0.9311, 1.3430],\n",
      "        [1.1480, 0.5864]])\n"
     ]
    }
   ],
   "source": [
    "# Element wise multiplication\n",
    "z = x * y\n",
    "print(z)\n",
    "z = torch.mul(x,y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9250, 0.4884],\n",
      "        [0.4662, 0.5201]])\n",
      "tensor([[0.9250, 0.4884],\n",
      "        [0.4662, 0.5201]])\n"
     ]
    }
   ],
   "source": [
    "# Element wise division\n",
    "z = x / y\n",
    "print(z)\n",
    "z = torch.div(x,y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2684, 0.2170, 0.7452],\n",
      "        [0.3298, 0.1474, 0.7473],\n",
      "        [0.2677, 0.3688, 0.6479],\n",
      "        [0.0950, 0.8245, 0.2827],\n",
      "        [0.1686, 0.6487, 0.7858]])\n",
      "tensor([0.2684, 0.3298, 0.2677, 0.0950, 0.1686])\n",
      "tensor([0.3298, 0.1474, 0.7473])\n",
      "tensor(0.1474)\n",
      "0.1473594307899475\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5,3)\n",
    "print(x)\n",
    "# All rows and 1st column i-e 1st column of matrix\n",
    "print(x[:,0])\n",
    "# row 1 and all column i-e 2nd row of matrix\n",
    "print(x[1,:])\n",
    "# value at 1,1 positon\n",
    "print(x[1,1]) # This returns a tensor\n",
    "print(x[1,1].item()) # This returns a value if a single value is in tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0774, 0.8861, 0.1863, 0.9873],\n",
      "        [0.9181, 0.7235, 0.7341, 0.9848],\n",
      "        [0.9756, 0.5280, 0.7638, 0.1453],\n",
      "        [0.8292, 0.0211, 0.2250, 0.2507]])\n",
      "torch.Size([4, 4])\n",
      "tensor([0.0774, 0.8861, 0.1863, 0.9873, 0.9181, 0.7235, 0.7341, 0.9848, 0.9756,\n",
      "        0.5280, 0.7638, 0.1453, 0.8292, 0.0211, 0.2250, 0.2507])\n",
      "torch.Size([16])\n",
      "tensor([[0.0774, 0.8861, 0.1863, 0.9873, 0.9181, 0.7235, 0.7341, 0.9848],\n",
      "        [0.9756, 0.5280, 0.7638, 0.1453, 0.8292, 0.0211, 0.2250, 0.2507]])\n",
      "torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(4,4)\n",
    "print(x)\n",
    "print(x.size())\n",
    "# converting to 1D from 2D\n",
    "y = x.view(16)\n",
    "print(y)\n",
    "print(y.size())\n",
    "# If -1 is used pytorch will automatically determine the dimension\n",
    "y = x.view(-1,8)\n",
    "print(y)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting From/To Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert from tensor to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "<class 'torch.Tensor'>\n",
      "[1. 1. 1. 1. 1.]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)\n",
    "print(type(a))\n",
    "b = a.numpy()\n",
    "print(b)\n",
    "print(type(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Here if both tensor and numpy array are in CPU then both of them will share same memory location so changing one variable will affect another and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a)\n",
    "# Here we can see than b is also changed when a was changed\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert from numpy to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.] <class 'numpy.ndarray'>\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64) <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "a = np.ones(5)\n",
    "print(a,type(a))\n",
    "b = torch.from_numpy(a)\n",
    "print(b,type(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6. 6. 6. 6. 6.]\n",
      "tensor([6., 6., 6., 6., 6.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Also in this case both share same location in memory\n",
    "a += 5\n",
    "print(a)\n",
    "print(b) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if cuda is available to run tensors in GPU  \n",
    "Also GPU tensors cannot be converted back to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd\n",
    "- It is used to calculate gradients in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.2260, -0.5951, -0.6820], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# This parameter is kept to true when we need to calculate gradients\n",
    "x = torch.randn(3,requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we perform operations on such tensors we can see a grad_fn parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7740, 1.4049, 1.3180], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x + 2\n",
    "print(y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.1980, 3.9473, 3.4742], grad_fn=<MulBackward0>)\n",
      "tensor([-2.4541,  4.1482, -1.8329])\n"
     ]
    }
   ],
   "source": [
    "z = y*y*2\n",
    "print(z)\n",
    "# this calculates gradient\n",
    "# * For a vector variable z we need to pass a gradient argument by creating vector of same size \n",
    "v = torch.tensor([0.1,1.0,0.001],dtype=torch.float32)\n",
    "z.backward(v) #dz/dx\n",
    "# To print the calculated gradients\n",
    "print(x.grad) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8732, grad_fn=<MeanBackward0>)\n",
      "tensor([1.0319, 1.8731, 1.7573])\n"
     ]
    }
   ],
   "source": [
    "z = z.mean()\n",
    "print(z)\n",
    "# this calculates gradient\n",
    "# * For a scalar variable z we don't need to send another parameter in the backward function\n",
    "z.backward() #dz/dx\n",
    "# To print the calculated gradients\n",
    "print(x.grad) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing require grad attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7310, 0.6867, 0.5042], requires_grad=True)\n",
      "tensor([0.7310, 0.6867, 0.5042])\n",
      "tensor([0.7310, 0.6867, 0.5042])\n",
      "tensor([2.7310, 2.6867, 2.5042], grad_fn=<AddBackward0>)\n",
      "tensor([2.7310, 2.6867, 2.5042])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3,requires_grad=True)\n",
    "print(x)\n",
    "# * 3 methods\n",
    "# x.requires_grad_(False)\n",
    "x.requires_grad_(False)\n",
    "print(x)\n",
    "x.requires_grad_(True)\n",
    "# x.detach()\n",
    "y = x.detach()\n",
    "print(y)\n",
    "# with torch.no_grad():\n",
    "y=x+2\n",
    "print(y)\n",
    "with torch.no_grad():\n",
    "    y=x+2\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the gradients will be accumulated in the grad attribute of the tensor, so we may need to reset the grad attribute in case of multiple iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1.])\n",
      "tensor([1., 1., 1., 1.])\n",
      "tensor([1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "weights = torch.ones(4,requires_grad=True)\n",
    "for epoch in range(3):\n",
    "    model_output = (weights+3).sum()\n",
    "    model_output.backward()\n",
    "    print(weights.grad)\n",
    "    # to reset the gradients in every iteration\n",
    "    weights.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each operation we perform pytorch creates a computational graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., requires_grad=True)\n",
      "tensor(1., grad_fn=<PowBackward0>)\n",
      "tensor(-2.)\n",
      "tensor(-1., grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(1.0)\n",
    "y = torch.tensor(2.0)\n",
    "\n",
    "# weights\n",
    "w = torch.tensor(1.0,requires_grad=True)\n",
    "print(w)\n",
    "\n",
    "# forward pass and compute the loss\n",
    "y_hat = w*x\n",
    "loss = (y_hat-y)**2\n",
    "\n",
    "print(loss)\n",
    "\n",
    "# backward pass\n",
    "loss.backward()\n",
    "print(w.grad)\n",
    "\n",
    "# update weights\n",
    "w = w + w.grad \n",
    "print(w)\n",
    "# next forward and backward pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual Way using numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training:  f(5) = 0.000\n",
      "epoch 1: w=1.200, loss = 30.00000000\n",
      "epoch 2: w=1.680, loss = 4.79999924\n",
      "epoch 3: w=1.872, loss = 0.76800019\n",
      "epoch 4: w=1.949, loss = 0.12288000\n",
      "epoch 5: w=1.980, loss = 0.01966083\n",
      "epoch 6: w=1.992, loss = 0.00314574\n",
      "epoch 7: w=1.997, loss = 0.00050331\n",
      "epoch 8: w=1.999, loss = 0.00008053\n",
      "epoch 9: w=1.999, loss = 0.00001288\n",
      "epoch 10: w=2.000, loss = 0.00000206\n",
      "epoch 11: w=2.000, loss = 0.00000033\n",
      "epoch 12: w=2.000, loss = 0.00000005\n",
      "epoch 13: w=2.000, loss = 0.00000001\n",
      "epoch 14: w=2.000, loss = 0.00000000\n",
      "epoch 15: w=2.000, loss = 0.00000000\n",
      "epoch 16: w=2.000, loss = 0.00000000\n",
      "epoch 17: w=2.000, loss = 0.00000000\n",
      "epoch 18: w=2.000, loss = 0.00000000\n",
      "epoch 19: w=2.000, loss = 0.00000000\n",
      "epoch 20: w=2.000, loss = 0.00000000\n",
      "Prediction after training:  f(5) = 10.000\n"
     ]
    }
   ],
   "source": [
    "# f = w*x \n",
    "X = np.array([1,2,3,4],dtype=np.float32)\n",
    "Y = np.array([2,4,6,8],dtype=np.float32)\n",
    "\n",
    "w = 0.0\n",
    "\n",
    "# model prediction\n",
    "def forward(x):\n",
    "    return w*x\n",
    "\n",
    "# loss = MSE\n",
    "def loss(y,y_predicted):\n",
    "    return ((y_predicted-y)**2).mean()\n",
    "\n",
    "# gradient\n",
    "# MSE(e) = 1/N * (w*x -y)**2 \n",
    "# de/dw =  1/N * 2x*(w*x-y)\n",
    "def gradient(x,y,y_predicted):\n",
    "    return np.dot(2*x,y_predicted-y).mean()\n",
    "\n",
    "print(f'Prediction before training:  f(5) = {forward(5):.3f}')\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.01\n",
    "n_iters = 20\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # prediction = forward pass \n",
    "    y_pred = forward(X)\n",
    "    # loss\n",
    "    l = loss(Y,y_pred)\n",
    "    # gradients \n",
    "    dw = gradient(X, Y, y_pred)\n",
    "    # update weights\n",
    "    w -= learning_rate*dw \n",
    "\n",
    "    if epoch%1 == 0:\n",
    "        print(f'epoch {epoch+1}: w={w:.3f}, loss = {l:.8f}')\n",
    "\n",
    "print(f'Prediction after training:  f(5) = {forward(5):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatic way using pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training:  f(5) = 0.000\n",
      "epoch 1: w=0.300, loss = 30.00000000\n",
      "epoch 11: w=1.665, loss = 1.16278565\n",
      "epoch 21: w=1.934, loss = 0.04506890\n",
      "epoch 31: w=1.987, loss = 0.00174685\n",
      "epoch 41: w=1.997, loss = 0.00006770\n",
      "epoch 51: w=1.999, loss = 0.00000262\n",
      "epoch 61: w=2.000, loss = 0.00000010\n",
      "epoch 71: w=2.000, loss = 0.00000000\n",
      "epoch 81: w=2.000, loss = 0.00000000\n",
      "epoch 91: w=2.000, loss = 0.00000000\n",
      "Prediction after training:  f(5) = 10.000\n"
     ]
    }
   ],
   "source": [
    "# f = w*x \n",
    "X = torch.tensor([1,2,3,4],dtype=torch.float32)\n",
    "Y = torch.tensor([2,4,6,8],dtype=torch.float32)\n",
    "\n",
    "w = torch.tensor(0.0,dtype=torch.float32,requires_grad=True)\n",
    "\n",
    "# model prediction\n",
    "def forward(x):\n",
    "    return w*x\n",
    "\n",
    "# loss = MSE\n",
    "def loss(y,y_predicted):\n",
    "    return ((y_predicted-y)**2).mean()\n",
    "\n",
    "# gradient will be using pytorch\n",
    "\n",
    "print(f'Prediction before training:  f(5) = {forward(5):.3f}')\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.01\n",
    "n_iters = 100\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # prediction = forward pass \n",
    "    y_pred = forward(X)\n",
    "    # loss\n",
    "    l = loss(Y,y_pred)\n",
    "    # gradients = backward pass\n",
    "    l.backward() #dl/dx\n",
    "    # update weights\n",
    "    with torch.no_grad():\n",
    "        w -= learning_rate*w.grad\n",
    "    \n",
    "    # zero gradients\n",
    "    w.grad.zero_()\n",
    "\n",
    "    if epoch%10 == 0:\n",
    "        print(f'epoch {epoch+1}: w={w:.3f}, loss = {l:.8f}')\n",
    "\n",
    "print(f'Prediction after training:  f(5) = {forward(5):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using pytorch functions for loss and optimization instead of custom fuctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training:  f(5) = 0.000\n",
      "epoch 1: w=0.300, loss = 30.00000000\n",
      "epoch 11: w=1.665, loss = 1.16278565\n",
      "epoch 21: w=1.934, loss = 0.04506890\n",
      "epoch 31: w=1.987, loss = 0.00174685\n",
      "epoch 41: w=1.997, loss = 0.00006770\n",
      "epoch 51: w=1.999, loss = 0.00000262\n",
      "epoch 61: w=2.000, loss = 0.00000010\n",
      "epoch 71: w=2.000, loss = 0.00000000\n",
      "epoch 81: w=2.000, loss = 0.00000000\n",
      "epoch 91: w=2.000, loss = 0.00000000\n",
      "Prediction after training:  f(5) = 10.000\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn \n",
    "# f = w*x \n",
    "X = torch.tensor([1,2,3,4],dtype=torch.float32)\n",
    "Y = torch.tensor([2,4,6,8],dtype=torch.float32)\n",
    "\n",
    "w = torch.tensor(0.0,dtype=torch.float32,requires_grad=True)\n",
    "\n",
    "# model prediction\n",
    "def forward(x):\n",
    "    return w*x\n",
    "\n",
    "\n",
    "# gradient will be using pytorch\n",
    "\n",
    "print(f'Prediction before training:  f(5) = {forward(5):.3f}')\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.01\n",
    "n_iters = 100\n",
    "\n",
    "# loss provided by pytorch\n",
    "loss = nn.MSELoss()\n",
    "# SGD => Stochastic Gradient Descent\n",
    "optimizer = torch.optim.SGD([w],lr=learning_rate)\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # prediction = forward pass \n",
    "    y_pred = forward(X)\n",
    "    # loss\n",
    "    l = loss(Y,y_pred)\n",
    "    # gradients = backward pass\n",
    "    l.backward() #dl/dx\n",
    "    # update weights\n",
    "    # no need to manually update weights\n",
    "    optimizer.step()\n",
    "    \n",
    "    # zero gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if epoch%10 == 0:\n",
    "        print(f'epoch {epoch+1}: w={w:.3f}, loss = {l:.8f}')\n",
    "\n",
    "print(f'Prediction after training:  f(5) = {forward(5):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Pytorch model to replace manually implemented forward pass function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training:  f(5) = -0.184\n",
      "epoch 1: w=0.327, loss = 32.22016144\n",
      "epoch 11: w=1.631, loss = 0.85408729\n",
      "epoch 21: w=1.843, loss = 0.04138092\n",
      "epoch 31: w=1.880, loss = 0.01923186\n",
      "epoch 41: w=1.889, loss = 0.01760177\n",
      "epoch 51: w=1.893, loss = 0.01656403\n",
      "epoch 61: w=1.896, loss = 0.01559958\n",
      "epoch 71: w=1.899, loss = 0.01469158\n",
      "epoch 81: w=1.902, loss = 0.01383645\n",
      "epoch 91: w=1.905, loss = 0.01303109\n",
      "Prediction after training:  f(5) = 9.810\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn \n",
    "# f = w*x \n",
    "X = torch.tensor([[1],[2],[3],[4]],dtype=torch.float32)\n",
    "Y = torch.tensor([[2],[4],[6],[8]],dtype=torch.float32)\n",
    "\n",
    "# test tensor for prediction\n",
    "X_test = torch.tensor([5],dtype=torch.float32)\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "input_size = n_features\n",
    "output_size = n_features\n",
    "\n",
    "# model prediction\n",
    "model = nn.Linear(in_features=input_size, out_features=output_size)\n",
    "\n",
    "# for multi layer model\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self,input_dim,output_dim):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        # define layers\n",
    "        self.lin = nn.Linear(input_dim,output_dim)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.lin(x)\n",
    "\n",
    "model = LinearRegression(input_size, output_size)\n",
    "\n",
    "# gradient will be using pytorch\n",
    "\n",
    "print(f'Prediction before training:  f(5) = {model(X_test).item():.3f}')\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.01\n",
    "n_iters = 100\n",
    "\n",
    "# loss provided by pytorch\n",
    "loss = nn.MSELoss()\n",
    "# SGD => Stochastic Gradient Descent\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # prediction = forward pass \n",
    "    y_pred = model(X)\n",
    "    # loss\n",
    "    l = loss(Y,y_pred)\n",
    "    # gradients = backward pass\n",
    "    l.backward() #dl/dx\n",
    "    # update weights\n",
    "    # no need to manually update weights\n",
    "    optimizer.step()\n",
    "    \n",
    "    # zero gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if epoch%10 == 0:\n",
    "        [w,b] = model.parameters()\n",
    "        print(f'epoch {epoch+1}: w={w[0][0].item():.3f}, loss = {l:.8f}')\n",
    "\n",
    "print(f'Prediction after training:  f(5) = {model(X_test).item():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('.aivenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a6aa66c812e617fe7a976665f04a60359ca2a7b0fa520cb928d0804dda4cd71e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
